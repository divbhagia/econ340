\documentclass{./../div_teaching_slides}

\begin{document}
\title{ECON 340 \\ Economic Research Methods}
\author{Div Bhagia}
\date{Lecture 11: Independence \& Correlation}

%%%%%%%%%%%% 
\begin{frame}[noframenumbering, plain]
\maketitle
\end{frame}

%%%%%%%%%%%% 
\begin{frame}{Random Variables}
\begin{witemize}
  \item \textit{Random variables} take different values under different scenarios.
  \item Examples:  outcome from a coin toss or a die roll, or number of times your wireless network fails before a deadline, etc.
  \item The likelihood of these scenarios is summarized by the probability distribution.
  \item Random variables can be \textit{discrete} or \textit{continuous}
\end{witemize}
\end{frame}


%%%%%%%%%%%% 
\begin{frame}{Two Random Variables}
  The \textit{joint probability distribution} of two discrete random variables is the probability that the random variables simultaneously take on certain
values.
$$ f(x,y) = Pr(X=x, Y=y)  $$
\vspace{0.25em}

\centering \small
\begin{tabularx}{0.95\textwidth}{cccc}
\toprule
	& Rain $(X=1)$ & No Rain $(X=0)$ & Total \\
	\midrule
60-min commute ($Y=60$) & 0.3  & 0.2 \\ 
30-min commute ($Y=30$) & 0.1 & 0.4 \\
\midrule
 Total & &  & \\
 \bottomrule
\end{tabularx}
\end{frame}

%%%%%%%%%%%% 
\begin{frame}{Marginal Distribution}
The \textit{marginal probability distribution} of a random variable $Y$ is just another name for its probability distribution. \\~\\
$$ f(y) = Pr(Y=y) = \sum_{x} Pr(X=x, Y=y) $$
\end{frame}

%%%%%%%%%%%% 
\begin{frame}{Conditional Distribution}
The distribution of a random variable $Y$ conditional on another random variable $X$ taking on a specific value is called the conditional
distribution of $Y$ given $X$.
$$ f(y|x) = Pr(Y=y| X=x) = \frac{Pr(X=x, Y=y)}{Pr(X=x)} = \frac{f(x,y)}{f(x)}   $$
\end{frame}

%%%%%%%%%%%% 
\begin{frame}{Commute Times}
 \small
\begin{center}
\begin{tabularx}{0.95\textwidth}{cccc}
\toprule
	& Rain $(X=1)$ & No Rain $(X=0)$ & Total \\
	\midrule
60-min commute ($Y=60$)  & 0.3  & 0.2 \\ 
30-min commute ($Y=30$) & 0.1 & 0.4 \\
\midrule
 Total & &  & \\
 \bottomrule
\end{tabularx} 
\end{center}
\vspace{6cm}
\end{frame}

%%%%%%%%%%%% 
\begin{frame}{Conditional Expectation}
The \textit{conditional expectation} of $Y$ given $X$ is the mean of the conditional distribution of $Y$ given $X$. \\~\\
$$ E(Y|X=x) = \sum_{y} y Pr(Y=y | X=x) = \sum_{y} y \cdot f(y|x) $$

\vspace{1em}
Calculate $E(Y| X=1)$ and $E(Y| X=0)$ in the last example. Comparing these tells us how $X$ affects $Y$. \\~\\
Can define conditional variance similarly. 
\end{frame}


%%%%%%%%%%%% 
\begin{frame}{Independence}
Two random variables $X$ and $Y$ are independently distributed, or independent, if knowing the value of one of the variables provides no information about the other.
$$ Pr(Y=y | X=x) = Pr(Y=y)  $$
%$$ Pr(X=x| Y=y) = Pr(X=x) Pr(Y=y)  $$
\textit{Example}: Two consecutive coin tosses. \\~\\
Note: We can equivalently say that $X$ and $Y$ are independent if $E(Y|X) = E(Y)$.
\end{frame}

%%%%%%%%%%%% 
\begin{frame}{Covariance and Correlation}
Covariance is a measure of the extent to which two random variables move
together. \\~\\
Let $X$ and $Y$ be a pair of random variables, then the \textit{covariance} of $X$ and $Y$ is given by:
$$ \sigma_{XY} = Cov(X,Y) = E[(X-\mu_X)(Y-\mu_Y)] = E(XY)-\mu_X \mu_Y $$ 
\vspace{0.15em}

The \textit{correlation} between $X$ and $Y$ is given by:
$$ \rho_{XY} = corr(X,Y) = \frac{Cov(X,Y)}{\sigma_X \sigma_Y} \quad \text{ where } -1 \leq \rho \leq 1$$
\end{frame}

%%%%%%%%%%%% 
\begin{frame}{Uncorrelated vs Independence}
%$X$ and $Y$ are uncorrelated if $\rho_{XY}=\sigma_{XY}=0$ i.e. $E(XY)=E(X)E(Y)$. \\~\\
If $X$ and $Y$ are independent, then they are also uncorrelated. 
$$ E(Y|X) = E(Y) \rightarrow \rho_{XY} = 0 $$
However, it is not necessarily true that if $X$ and $Y$ are uncorrelated, then they are also independent. \\~\\
\end{frame}

%%%%%%%%%%%% 
\begin{frame}{Sums of Random Variables}
$X$ and $Y$ is a pair of random variables, then
$$ E(aX+bY) = aE(X) + bE(Y) $$
$$ Var(aX+bY) = a^2Var(X) + b^2 Var(Y) + 2 ab Cov(X,Y) $$

\vspace{1em}
If $X$ and $Y$ are independent:
$$ Var(aX+bY) = a^2 Var(X) + b^2 Var(Y) $$
\end{frame}

%%%%%%%%%%%% 
\begin{frame}{Portfolio Diversification}
You are now contemplating between two stocks with the same average return and spread.  
$$ \mu_X = \mu_Y \quad \quad \sigma^2_X = \sigma^2_Y $$
Should you pick any one stock at random or invest equally in both?
\end{frame}

% %%%%%%%%%%%%%%%%%%%%
% \begin{frame}{What's next?}
% \begin{witemize}
%   \item Research Paper Submission 1 is due by end of the day today
%   \item I reorganized some material on Canvas and posted filled version of our in-class handouts for your reference. Let me know if you have trouble finding any of the material. 
%   \item Problem Set 3 is now posted on Canvas (due next week). You can attempt Questions 1 and 2. 
%   \item Thursday: Start with Sampling and Estimation. 
% \end{witemize}

%\end{frame}


\end{document}